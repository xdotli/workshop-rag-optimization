{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hybrid Search: dense and sparse vectors\n",
    "\n",
    "LlamaIndex integration with Qdrant supports sparse embeddings as well. From the user perspective, it doesn't change much, as they interact through the same interface. Since sparse and dense vectors work best in different setups, it makes sense to combine them if we want to have the best of both worlds. There are, however, some parameters we can control.\n",
    "\n",
    "Let's again start with recreating our pipeline, but this time we will use the other collection that has sparse vectors as well.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3b7af9ec8fca084"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "660547c536bbfa43",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=\"local:BAAI/bge-large-en\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44f2eda9a0c435d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "import os\n",
    "\n",
    "client = QdrantClient(\n",
    "    os.environ.get(\"QDRANT_URL\"), \n",
    "    api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    ")\n",
    "vector_store_hybrid = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"hacker-news-hybrid\",\n",
    "    enable_hybrid=True,\n",
    "    batch_size=20,  # this is important for the ingestion\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31fc9049413d2075",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store_hybrid,\n",
    "    service_context=service_context,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acdcf928f564b071",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Differences between sparse and dense vectors\n",
    "\n",
    "Sparse vectors are usually used in high-dimensional spaces, where the majority of the elements are zero. A single dimension represents a single word, so the dimensionality of the space is equal to the size of the vocabulary, with just a few non-zero values. \n",
    "\n",
    "There are various ways to create sparse vectors, but the most common one is to use the TF-IDF or BM25 representation. It's a simple and effective way to represent the importance of words in a document and in many cases create a solid baseline for the search.\n",
    "\n",
    "LlamaIndex uses SPLADE by default, which is based on transformers, similar to dense embedding models. **The main advantage of using sparse vectors is that they overcome the problem of vocabulary mismatch**. If a word is not present in the vocabulary of the dense embedding model, we can still represent it using the sparse vectors."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1aa7483e19c702"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using sparse vectors only\n",
    "\n",
    "Before we dive into the hybrid search, let's see what might be achieved by using sparse vectors alone. We already know the nodes retrieved by dense vectors so it makes sense to compare the results returned by both methods."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbd696863d4c0144"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.types import VectorStoreQueryMode\n",
    "from llama_index.indices.vector_store import VectorIndexRetriever\n",
    "\n",
    "sparse_retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.SPARSE,\n",
    "    sparse_top_k=5,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b724350a8f0a9fbd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nodes = sparse_retriever.retrieve(\"What is the best way to learn programming?\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4762c0e9b8fb0231",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hybrid search\n",
    "\n",
    "There are some specific use cases in which we may prefer to use just the sparse vectors. But both methods may complement each other and we usually need to find the sweet spot. The `VectorIndexRetriever` class allows us to control the parameters of the search. We can set the `sparse_top_k` and `similarity_top_k` parameters to control the number of results returned by each method. We can also set the `alpha` parameters to control the importance of each method (`0.0` = sparse, `1.0` = dense vectors only)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d05f74509f13f9c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hybrid_retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.HYBRID,\n",
    "    sparse_top_k=5,\n",
    "    similarity_top_k=5,\n",
    "    alpha=0.1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8aa7191e7ad214de",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nodes = hybrid_retriever.retrieve(\"What is the best way to learn programming?\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccbf546068405a4d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We shouldn't be modifying the alpha parameter after the retriever has been created\n",
    "# but that's the easiest way to show the effect of the parameter\n",
    "hybrid_retriever._alpha = 0.9\n",
    "\n",
    "nodes = hybrid_retriever.retrieve(\"What is the best way to learn programming?\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1290259a827c3f77",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "65af4ef3d86d61ac",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
