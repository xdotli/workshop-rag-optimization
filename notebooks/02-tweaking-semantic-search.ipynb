{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5527397e89ce8f7f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Tweaking up semantic retrieval\n",
    "\n",
    "There are various objectives we could try optimizing for when it comes to semantic retrieval. We could try to optimize the **speed** of the retrieval, the **quality** of it, or the **memory usage**. We'll review some of the techniques in all three areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97156bfd207c831",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Loading the configuration and pipeline\n",
    "\n",
    "Again, let's start with loading the configuration, and then set up our retriever. We don't want a full RAG pipeline, as we are solely interested in the semantic search part. Improving a single component at a time should be easier to understand and debug. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5400644c6fa94d96",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c571d2c60524ef3d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=\"local:BAAI/bge-large-en\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480e88c42e30d3cd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "import os\n",
    "\n",
    "client = QdrantClient(\n",
    "    os.environ.get(\"QDRANT_URL\"), \n",
    "    api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    ")\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client, \n",
    "    collection_name=\"hacker-news\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb26026d9b2d8e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44471047edccc2a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import MetadataFilters, MetadataFilter\n",
    "from llama_index.indices.vector_store import VectorIndexRetriever\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=5,\n",
    "    filters=MetadataFilters(\n",
    "        filters=[\n",
    "            MetadataFilter(key=\"type\", value=\"story\"),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fefadc69369516",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ask HN: Where do you go to find recommendations for physical programming books?\n",
      "\n",
      "I&#x27;m old school and like sitting down with a book both for learning actual coding and also for methodologies and philosophies. I don&#x27;t know where to go for recommendations. Any help? Thanks!\n",
      "\n",
      "2 Ask HN: What to learn in order to get a software job in a decent country?\n",
      "\n",
      "A good friend of mine is 18 and Russian. He is a programming prodigy and is trying to formulate a plan to get out. He&#x27;s thinking about his future CV and applying for jobs. What would be the best frameworks to invest time in getting experience with now?\n",
      "\n",
      "3 Ask HN: What is the best way to get into building electronics as a programmer?\n",
      "\n",
      "I am asking not only about learning what is taught in classes for solving ideal problems. I am talking about the real engineering like a hobbyist who actually understands what works in real life and how to build it properly.\n",
      "\n",
      "4 Ask HN: Best tools for 4/5 year old to learn programming?\n",
      "\n",
      "I&#x27;m looking for the best systems to help a 4&#x2F;5 year old get the basics of programming. My daughter has shown interest in what I do, and loves puzzles and building things. Looking for something visual and fun that can start her down the path of logic and creating with computers.<p>I have a passing familiarity with Scratch [1], which I&#x27;m now looking into more, but am hoping others can share their knowledge and experience in this area.<p>[1] https:&#x2F;&#x2F;scratch.mit.edu&#x2F;\n",
      "\n",
      "5 Ask HN: What is the best way to learn a new language?\n",
      "\n",
      "Is using a flashcard app like Anki the best way? Duolingo? Memrise? etc<p>For context, I was thinking of learning either Spanish, Dutch or Arabic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\"What is the best way to learn programming?\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8084e400f1ff37",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Quality optimization\n",
    "\n",
    "We have implemented a basic RAG already, and we might be happy with the quality. There are a lot of aspects when it comes to measuring the quality of a semantic retrieval system, and we will not go into details here. It is usually related to the quality of the embedding model we use, and it is a topic for another day.\n",
    "\n",
    "However, all the vector databases approximate the nearest neighbor search, and this approximation comes with a cost. The cost is that the results are not always ideal. HNSW, an algorithm used in Qdrant, has some parameters to control how the internal structures are built, and these parameters can be tweaked to improve the quality of the results. This is very specific to the vector database used, thus it's configured through the Qdrant API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18105b7cfb654cb6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=47037, indexed_vectors_count=45000, points_count=47037, segments_count=2, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1024, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None), payload_schema={'type': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=47037)})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(collection_name=\"hacker-news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7eb35651edebd8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "As for now, the most interesting part is the `hnsw_config` field. The algorithm itself is controlled by two parameters. The number of edges per node is called the `m` parameter. The larger the value, the higher the precision of the search, but the more space required. The `ef_construct` parameter is the number of neighbors to consider during the index building. Again, the larger the value, the higher the precision, but the longer the indexing time. \n",
    "\n",
    "Playing with both parameters **improves just the approximation of the exact nearest neighbors**, and a proper embedding model is still way more important. However, [this quality aspect might also be controlled, even in an automated way](https://qdrant.tech/documentation/tutorials/retrieval-quality/). For the time being, we'll simply increase both values, but won't measure the impact on the overall quality of search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3668e7f04e38d00f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "client.update_collection(\n",
    "    collection_name=\"hacker-news\",\n",
    "    hnsw_config=models.HnswConfigDiff(\n",
    "        m=32,\n",
    "        ef_construct=200,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c4d08884025a701",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=47037, indexed_vectors_count=45000, points_count=47037, segments_count=2, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1024, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=32, ef_construct=200, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None), payload_schema={'type': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=47037)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    collection = client.get_collection(\"hacker-news\")\n",
    "    if collection.status == models.CollectionStatus.GREEN:\n",
    "        break\n",
    "    time.sleep(1.0)\n",
    "        \n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a2ede02bc5281ec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ask HN: Where do you go to find recommendations for physical programming books?\n",
      "\n",
      "I&#x27;m old school and like sitting down with a book both for learning actual coding and also for methodologies and philosophies. I don&#x27;t know where to go for recommendations. Any help? Thanks!\n",
      "\n",
      "2 Ask HN: What to learn in order to get a software job in a decent country?\n",
      "\n",
      "A good friend of mine is 18 and Russian. He is a programming prodigy and is trying to formulate a plan to get out. He&#x27;s thinking about his future CV and applying for jobs. What would be the best frameworks to invest time in getting experience with now?\n",
      "\n",
      "3 Ask HN: What is the best way to get into building electronics as a programmer?\n",
      "\n",
      "I am asking not only about learning what is taught in classes for solving ideal problems. I am talking about the real engineering like a hobbyist who actually understands what works in real life and how to build it properly.\n",
      "\n",
      "4 Ask HN: Best tools for 4/5 year old to learn programming?\n",
      "\n",
      "I&#x27;m looking for the best systems to help a 4&#x2F;5 year old get the basics of programming. My daughter has shown interest in what I do, and loves puzzles and building things. Looking for something visual and fun that can start her down the path of logic and creating with computers.<p>I have a passing familiarity with Scratch [1], which I&#x27;m now looking into more, but am hoping others can share their knowledge and experience in this area.<p>[1] https:&#x2F;&#x2F;scratch.mit.edu&#x2F;\n",
      "\n",
      "5 Ask HN: What is the best way to learn a new language?\n",
      "\n",
      "Is using a flashcard app like Anki the best way? Duolingo? Memrise? etc<p>For context, I was thinking of learning either Spanish, Dutch or Arabic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\"What is the best way to learn programming?\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b5c8fd6513bb5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Memory optimization\n",
    "\n",
    "Each point in a Qdrant collection consists of up to three elements: id, vector(s), and optional payload represented by a JSON object. Vectors are indexed in an HNSW graph, and search operations may involve semantic similarity and some payload-based criteria (it's best to add payload indexes on the fields we want to use for the filtering). Ideally, all the elements should be kept in RAM so access is fast.\n",
    "\n",
    "Unfortunately, semantic search is a heavy operation in terms of memory requirements. However, some projects are implemented on a budget and can't afford machines with hundreds of gigabytes of RAM. Qdrant allows storing every single component on a disk to reduce memory usage, but that comes with a performance cost. Let's compare the efficiency of the operations with all the components in RAM and with some of them on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d2159e4871b1dd6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 ms ± 24.4 ms per loop (mean ± std. dev. of 5 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "retriever.retrieve(\"What is the best way to learn programming?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1534ffc86ce1f7e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.update_collection(\n",
    "    collection_name=\"hacker-news\",\n",
    "    hnsw_config=models.HnswConfigDiff(\n",
    "        on_disk=True,\n",
    "    ),\n",
    "    vectors_config={\n",
    "        \"\": models.VectorParamsDiff(\n",
    "            on_disk=True,\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "396074dc50565c7a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=47037, indexed_vectors_count=45000, points_count=47037, segments_count=2, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1024, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=True), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=32, ef_construct=200, full_scan_threshold=10000, max_indexing_threads=0, on_disk=True, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None), payload_schema={'type': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=47037)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    collection = client.get_collection(\"hacker-news\")\n",
    "    if collection.status == models.CollectionStatus.GREEN:\n",
    "        break\n",
    "    time.sleep(1.0)\n",
    "        \n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f500d12db05fdc6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 ms ± 20.5 ms per loop (mean ± std. dev. of 5 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "retriever.retrieve(\"What is the best way to learn programming?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9fc24e922f165",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Speed optimization\n",
    "\n",
    "There are various ways of optimizing semantic search in terms of speed. The most straightforward one is to reduce both `m` and `ef_construct` parameters, as we did in the previous section. However, this comes with a cost of the quality of the results.\n",
    "\n",
    "Qdrant also provides a number of quantization techniques, and two of them are primarily used to increase speed and reduce memory at the same time:\n",
    "\n",
    "1. **Scalar Quantization** - uses `int8` instead of `float32` to store each vector dimension\n",
    "2. **Binary Quantization** - `bool` values are used to store each vector dimension\n",
    "\n",
    "The first one reduces the memory usage by up to 4x, while the second one by up to 32x and both increase the speed of the search. However, the quality of the search results is reduced, and Binary Quantization is not suitable for all the use cases. It only works with some specific models, usually the ones with high dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1154f4172094cdf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "In our case, we're going to set up the binary quantization either way. From the LlamaIndex perspective, the search operations are going to be fired identically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e26ec00449bfb27",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.update_collection(\n",
    "    collection_name=\"hacker-news\",\n",
    "    quantization_config=models.BinaryQuantization(\n",
    "        binary=models.BinaryQuantizationConfig(\n",
    "            always_ram=True,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a01cc56dff3ea252",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=47037, indexed_vectors_count=45000, points_count=47037, segments_count=2, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1024, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=True), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=32, ef_construct=200, full_scan_threshold=10000, max_indexing_threads=0, on_disk=True, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=BinaryQuantization(binary=BinaryQuantizationConfig(always_ram=True))), payload_schema={'type': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=47037)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    collection = client.get_collection(\"hacker-news\")\n",
    "    if collection.status == models.CollectionStatus.GREEN:\n",
    "        break\n",
    "    time.sleep(1.0)\n",
    "        \n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f4d07f587535769",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ask HN: Where do you go to find recommendations for physical programming books?\n",
      "\n",
      "I&#x27;m old school and like sitting down with a book both for learning actual coding and also for methodologies and philosophies. I don&#x27;t know where to go for recommendations. Any help? Thanks!\n",
      "\n",
      "2 Ask HN: What to learn in order to get a software job in a decent country?\n",
      "\n",
      "A good friend of mine is 18 and Russian. He is a programming prodigy and is trying to formulate a plan to get out. He&#x27;s thinking about his future CV and applying for jobs. What would be the best frameworks to invest time in getting experience with now?\n",
      "\n",
      "3 Ask HN: What is the best way to get into building electronics as a programmer?\n",
      "\n",
      "I am asking not only about learning what is taught in classes for solving ideal problems. I am talking about the real engineering like a hobbyist who actually understands what works in real life and how to build it properly.\n",
      "\n",
      "4 Ask HN: Best tools for 4/5 year old to learn programming?\n",
      "\n",
      "I&#x27;m looking for the best systems to help a 4&#x2F;5 year old get the basics of programming. My daughter has shown interest in what I do, and loves puzzles and building things. Looking for something visual and fun that can start her down the path of logic and creating with computers.<p>I have a passing familiarity with Scratch [1], which I&#x27;m now looking into more, but am hoping others can share their knowledge and experience in this area.<p>[1] https:&#x2F;&#x2F;scratch.mit.edu&#x2F;\n",
      "\n",
      "5 Ask HN: What is the best way to learn a new language?\n",
      "\n",
      "Is using a flashcard app like Anki the best way? Duolingo? Memrise? etc<p>For context, I was thinking of learning either Spanish, Dutch or Arabic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\"What is the best way to learn programming?\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "408270c8449987c9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 ms ± 23.5 ms per loop (mean ± std. dev. of 5 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "retriever.retrieve(\"What is the best way to learn programming?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536dbd5e38b33efd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
